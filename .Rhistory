# Read the full data
my_yelp <- read_rds(here("Lab", "module_1", "week2", "yelp_all.geojson"))
# Issue 2 ------------------------------
# We do have many duplicated rows in our data, which is expected.
# Luckily, Yelp data provides a unique ID column for each business.
my_yelp %>%
distinct(id, .keep_all=T)
# Issue 2 ------------------------------
# We do have many duplicated rows in our data, which is expected.
# Luckily, Yelp data provides a unique ID column for each business.
yelp_unique <- my_yelp %>%
distinct(id, .keep_all=T)
# Read the full data
my_yelp <- read_rds(here("Lab", "module_2", "week2", "yelp_all.geojson"))
here("Lab", "module_1", "week2", "yelp_all.geojson")
# Read the full data
my_yelp <- st_read(here("Lab", "module_1", "week2", "yelp_all.geojson"))
yelp_all
ls()
# Prepare a collector
yelp_all_list <- vector("list", nrow(ready_4_yelp))
# Looping through all Census Tracts
for (row in 1:nrow(ready_4_yelp)){
yelp_all_list[[row]] <- suppressMessages(get_yelp(ready_4_yelp[row,], "restaurant"))
if (row %% 50 == 0){
print(paste0("Current row: ", row))
}
}
# Collapsing the list into a data.frame
yelp_all <- yelp_all_list %>% bind_rows() %>% as_tibble()
# print
yelp_all %>% print(width=1000)
yelp_all %>% write_rds(here("Lab", "module_1", "week2", "yelp_all.rds"))
yelp_all %>% select(categories, transactions, location) %>% slice(1:5) %>% write_rds(here("Lab", "module_1", "week2", "yelp_subset.rds"))
# Read the full data
my_yelp <- read_rds(here("Lab", "module_1", "week2", "yelp_all.rds"))
yelp_unique <- my_yelp %>%
distinct(id, .keep_all=T)
paste0(nrow(my_yelp), "->", nrow(yelp_unique))
yelp_unique <- my_yelp %>%
distinct(id, .keep_all=T)
paste0(nrow(my_yelp), " -> ", nrow(yelp_unique)) %>% print()
my_yelp %>%
apply(., 2, function(x) sum(is.na(x)))
my_yelp
yelp_unique %>% map(sum(is.na()))
yelp_unique %>% map(~sum(is.na(.x)))
xaringan:::inf_mr()
library(tidyverse)
library(sf)
library(here)
library(tmap)
library(tidyverse) # tidyr is included in tidyverse package.
# Toy dataset
toy_df <- data.frame(name = c("John", "Jane", "Mary"),
treatment_a = c(NA, 16, 3),
treatment_b = c(2, 11, 1),
treatment_c = c(6, 12, NA))
print(toy_df)
# pivot longer
(toy_long <- toy_df %>%
pivot_longer(cols = treatment_a:treatment_c,
names_to = 'treatment', # new column name for 'cols' in character
values_to = 'result')) # new name for the column storing the values in character
# back to wider
(toy_wide <- toy_long %>%
pivot_wider(id_cols = name, # unique identifier
names_from = treatment, # from which columns should the new column names come?
values_from = result)) # from which columns should the values come?
dupl_df <- data.frame(name = c("A", "A", "B", "C", "C", "C", "D"),
GPA = c(3.5, 3.5, 4.0, 2.0, 3.0, 3.0, 2.0))
# Base R
duplicated(dupl_df$name)
# Duplicates in column "name" removed.
dupl_df[!duplicated(dupl_df$name),]
# Returns a vector, not data frame
dupl_df %>%
distinct(name) # Try adding .keep_all = TRUE argument
# Returns a data frame
dupl_df %>%
distinct(name, GPA)
# A character vector to split
onecol_df <- data.frame(labels = c('a1','b_2','c_3_2','d_4_1'))
# split the character at _
onecol_df %>% separate(col = "labels", sep = "_", into = c("alphabet", "numeric"))
yelp_subset <- read_rds(here("Lab", "module_1", "week2", "yelp_subset.rds"))
yelp_subset %>%
tibble() %>%
print(width = 1000)
yelp_subset$coordinates
yelp_flat <- yelp_subset %>%
jsonlite::flatten() %>%
as_tibble() %>%
print(width = 1000)
yelp_flat$coordinates.latitude
# Concatenate what's inside the list
yelp_concat <- yelp_flat %>%
mutate(transactions = transactions %>%
map_chr(., function(x) str_c(x, collapse=", ")),
location.display_address = location.display_address %>%
map_chr(., function(x) str_c(x, collapse=", ")))
# Custom function that takes the data frame in "categories" column in Yelp data
# and returns a character vector
concate_list <- function(x){
# x is a data frame with columns "alias" and "title" from Yelp$categories
# returns a character vector containing category concatenated titles
titles <- x[["title"]] %>% str_c(collapse = ", ")
return(titles)
}
yelp_flat2 <- yelp_concat %>%
mutate(categories = categories %>% map_chr(concate_list)) %>%
print(width = 1000)
yelp_flat2 %>% print(width = 1000)
# Dropping NA using is.na()
toy_df %>%
filter(!is.na(treatment_a))
# This check across all columns and drops all rows that have at least one NA.
toy_df %>%
drop_na()
my_yelp <- read_rds(here("Lab", "module_1", "week2", "yelp_all.rds"))
# Issue 1 ------------------------------
# We don't seem to have this issue for Yelp data.
# Issue 2 ------------------------------
# We do have many duplicated rows in our data, which is expected.
# Luckily, Yelp data provides a unique ID column for each business.
yelp_unique <- my_yelp %>%
distinct(id, .keep_all=T)
paste0(nrow(my_yelp), " -> ", nrow(yelp_unique)) %>% print()
yelp_flat %>% head()
yelp_unique <- my_yelp %>%
distinct(id, .keep_all=T)
yelp_unique
yelp_flat <- yelp_unique %>%
# 1. Flattening columns with data frame
jsonlite::flatten()
yelp_flat
yelp_flat %>% head()
yelp_flat <- yelp_unique %>%
# 1. Flattening columns with data frame
jsonlite::flatten() %>%
# 2. Handling list-columns
mutate(transactions = transactions %>%
map_chr(., function(x) str_c(x, collapse=", ")),
location.display_address = location.display_address %>%
map_chr(., function(x) str_c(x, collapse=", ")),
categories = categories %>% map_chr(concate_list)) # concate_list is the custom function
yelp_flat %>% tibble
yelp_flat %>% tibble %>% print(width = 1000)
yelp_flat %>%
map(., function(x) sum(is.na(x)))
# Issue 4 ------------------------------
# Let's first check whether there are any NAs.
yelp_flat %>%
map_dbl(., function(x) sum(is.na(x)))
library(github)
Sys.getenv("GITHUB_TOKEN")
library(tidyverse)
library(sf)
library(here)
library(tmap)
library(tidyverse) # tidyr is included in tidyverse package.
# Toy dataset
toy_df <- data.frame(name = c("John", "Jane", "Mary"),
treatment_a = c(NA, 16, 3),
treatment_b = c(2, 11, 1),
treatment_c = c(6, 12, NA))
print(toy_df)
# pivot longer
(toy_long <- toy_df %>%
pivot_longer(cols = treatment_a:treatment_c,
names_to = 'treatment', # new column name for 'cols' in character
values_to = 'result')) # new name for the column storing the values in character
# back to wider
(toy_wide <- toy_long %>%
pivot_wider(id_cols = name, # unique identifier
names_from = treatment, # from which columns should the new column names come?
values_from = result)) # from which columns should the values come?
dupl_df <- data.frame(name = c("A", "A", "B", "C", "C", "C", "D"),
GPA = c(3.5, 3.5, 4.0, 2.0, 3.0, 3.0, 2.0))
# Base R
duplicated(dupl_df$name)
# Duplicates in column "name" removed.
dupl_df[!duplicated(dupl_df$name),]
# Returns a vector, not data frame
dupl_df %>%
distinct(name) # Try adding .keep_all = TRUE argument
# Returns a data frame
dupl_df %>%
distinct(name, GPA)
# A character vector to split
onecol_df <- data.frame(labels = c('a1','b_2','c_3_2','d_4_1'))
# split the character at _
onecol_df %>% separate(col = "labels", sep = "_", into = c("alphabet", "numeric"))
yelp_subset <- read_rds(here("Lab", "module_1", "week2", "yelp_subset.rds"))
yelp_subset %>%
tibble() %>%
print(width = 1000)
yelp_subset$coordinates
yelp_flat <- yelp_subset %>%
jsonlite::flatten() %>%
as_tibble() %>%
print(width = 1000)
yelp_flat$coordinates.latitude
# Concatenate what's inside the list
yelp_concat <- yelp_flat %>%
mutate(transactions = transactions %>%
map_chr(., function(x) str_c(x, collapse=", ")),
location.display_address = location.display_address %>%
map_chr(., function(x) str_c(x, collapse=", ")))
# Custom function that takes the data frame in "categories" column in Yelp data
# and returns a character vector
concate_list <- function(x){
# x is a data frame with columns "alias" and "title" from Yelp$categories
# returns a character vector containing category concatenated titles
titles <- x[["title"]] %>% str_c(collapse = ", ")
return(titles)
}
yelp_flat2 <- yelp_concat %>%
mutate(categories = categories %>% map_chr(concate_list)) %>%
print(width = 1000)
yelp_flat2 %>% print(width = 1000)
# Dropping NA using is.na()
toy_df %>%
filter(!is.na(treatment_a))
# This check across all columns and drops all rows that have at least one NA.
toy_df %>%
drop_na()
# Read the full data
my_yelp <- read_rds(here("Lab", "module_1", "week2", "yelp_all.rds"))
# Issue 1 ------------------------------
# We don't seem to have this issue for Yelp data.
# Issue 2 ------------------------------
# We do have many duplicated rows in our data, which is expected.
# Luckily, Yelp data provides a unique ID column for each business.
yelp_unique <- my_yelp %>%
distinct(id, .keep_all=T)
paste0(nrow(my_yelp), " -> ", nrow(yelp_unique)) %>% print()
# Issue 3 ------------------------------
# This is the main issue in Yelp data, caused by the original data format being JSON.
yelp_flat <- yelp_unique %>%
# 1. Flattening columns with data frame
jsonlite::flatten() %>%
# 2. Handling list-columns
mutate(transactions = transactions %>%
map_chr(., function(x) str_c(x, collapse=", ")),
location.display_address = location.display_address %>%
map_chr(., function(x) str_c(x, collapse=", ")),
categories = categories %>% map_chr(concate_list)) # concate_list is the custom function
# Issue 4 ------------------------------
# Let's first check whether there are any NAs.
yelp_flat %>%
map_dbl(., function(x) sum(is.na(x)))
# There seems to be many missing values in price and location information.
# Remember that you do not need to drop rows just because the row has NAs in some columns IF YOU DON"T NEED THAT COLUMN FOR YOUR ANALYSIS. In this dataset, missing values in location.address1 are not problem because we have cooridnate information.
# --> There seems to be many missing values in 'price' and 'location' columns.
# Remember that you do not need to drop rows just because the row has NAs in some columns IF YOU DON"T NEED THAT COLUMN FOR YOUR ANALYSIS. In this dataset, missing values in location.address1 are not problem because we have coordidnate information. We, however, must drop the four NAs in coordinates.latitude and coordinates.longitude.
identical(is.na(yelp_flat$coordinates.latitude),
is.na(yelp_flat$coordinates.longitude),)
yelp_flat %>%
drop_na(coordinates.longitude)
yelp_flat %>%
drop_na(coordinates.longitude)
nrow(yelp_flat)
nrow(yelp_coord)
# Drop them.
yelp_coord <- yelp_flat %>%
drop_na(coordinates.longitude)
nrow(yelp_coord)
# Drop them.
yelp_dropna1 <- yelp_flat %>%
drop_na(coordinates.longitude)
# Missing values in 'price' column can be an issue, as that's one of the main variables. Assuming that we will be using the price column, let's drop NAs in 'price' column too.
yelp_dropna2 <- yelp_dropna1 %>%
drop_na(price)
yelp_dropna2
nrow(yelp_dropna2)
nrow(yelp_flat2)
nrow(yelp_flat)
# Issue 4 ------------------------------
# Let's first check whether there are any NAs.
yelp_flat %>%
map_dbl(., function(x) sum(is.na(x)))
# census boundary
census <- st_read("https://raw.githubusercontent.com/BonwooKoo/UrbanAnalytics2022/main/Lab/module_0/testdata.geojson") %>%
filter(county %in% c("Fulton County", "DeKalb County")) %>%
st_union()
# sf subsets
yelp_in <- yelp_dropna2[census, ,op = st_intersects]
yelp_dropna2$coordinates.latitude
yelp_dropna2$coordinates.longitude
# Converting yelp_dropna2 into a sf object
yelp_sf <- yelp_dropna2 %>%
st_as_sf(coords=c("coordinates.longitude", "coordinates.latitude"), crs = 4326)
yelp_sf
# census boundary
census <- st_read("https://raw.githubusercontent.com/BonwooKoo/UrbanAnalytics2022/main/Lab/module_0/testdata.geojson") %>%
filter(county %in% c("Fulton County", "DeKalb County")) %>%
st_union()
# Converting yelp_dropna2 into a sf object
yelp_sf <- yelp_dropna2 %>%
st_as_sf(coords=c("coordinates.longitude", "coordinates.latitude"), crs = 4326)
# sf subsets
yelp_in <- yelp_sf[census, ,op = st_intersects]
# Visualize
tmap_mode("view")
map_in <- tm_shape(yelp_in) + tm_dots()
yelp_dropna2 %>% head()
factor(yelp_dropna2$price)
lm(review_count ~ price, data = yelp_dropna2)
table(yelp_dropna2$location.state)
table(yelp_in$location.state)
yelp_in %>% filter(location.state == 'NE') %>% tm_shape() +tm_dots
yelp_in %>% filter(location.state == 'NE') %>% tm_shape() +tm_dots()
glue::glue("hi {nrow(yelp_in)}")
source("~/.active-rstudio-document", echo=TRUE)
?st_join
census
# census is currently sfc. Convert it to sf.
census_sf <- census %>% st_sf()
census_sf
census_sf
census
tm_shape(census_yelp) + tm_polygons(col = "review_count")
library(tidyverse)
library(sf)
library(here)
library(tmap)
library(tidyverse) # tidyr is included in tidyverse package.
# Toy dataset
toy_df <- data.frame(name = c("John", "Jane", "Mary"),
treatment_a = c(NA, 16, 3),
treatment_b = c(2, 11, 1),
treatment_c = c(6, 12, NA))
print(toy_df)
# pivot longer
(toy_long <- toy_df %>%
pivot_longer(cols = treatment_a:treatment_c,
names_to = 'treatment', # new column name for 'cols' in character
values_to = 'result')) # new name for the column storing the values in character
# back to wider
(toy_wide <- toy_long %>%
pivot_wider(id_cols = name, # unique identifier
names_from = treatment, # from which columns should the new column names come?
values_from = result)) # from which columns should the values come?
dupl_df <- data.frame(name = c("A", "A", "B", "C", "C", "C", "D"),
GPA = c(3.5, 3.5, 4.0, 2.0, 3.0, 3.0, 2.0))
# Base R
duplicated(dupl_df$name)
# Duplicates in column "name" removed.
dupl_df[!duplicated(dupl_df$name),]
# Returns a vector, not data frame
dupl_df %>%
distinct(name) # Try adding .keep_all = TRUE argument
# Returns a data frame
dupl_df %>%
distinct(name, GPA)
# A character vector to split
onecol_df <- data.frame(labels = c('a1','b_2','c_3_2','d_4_1'))
# split the character at _
onecol_df %>% separate(col = "labels", sep = "_", into = c("alphabet", "numeric"))
yelp_subset <- read_rds(here("Lab", "module_1", "week2", "yelp_subset.rds"))
yelp_subset %>%
tibble() %>%
print(width = 1000)
yelp_subset$coordinates %>% head()
yelp_flat <- yelp_subset %>%
jsonlite::flatten() %>%
as_tibble()
yelp_flat$coordinates.latitude %>% head()
# Concatenate what's inside the list
yelp_concat <- yelp_flat %>%
mutate(transactions = transactions %>%
map_chr(., function(x) str_c(x, collapse=", ")),
location.display_address = location.display_address %>%
map_chr(., function(x) str_c(x, collapse=", ")))
# Custom function that takes the data frame in "categories" column in Yelp data
# and returns a character vector
concate_list <- function(x){
# x is a data frame with columns "alias" and "title" from Yelp$categories
# returns a character vector containing category concatenated titles
titles <- x[["title"]] %>% str_c(collapse = ", ")
return(titles)
}
yelp_flat2 <- yelp_concat %>%
mutate(categories = categories %>% map_chr(concate_list)) %>%
print(width = 1000)
yelp_flat2 %>% print(width = 1000)
# Dropping NA using is.na()
toy_df %>%
filter(!is.na(treatment_a))
# This check across all columns and drops all rows that have at least one NA.
toy_df %>%
drop_na()
# Read the full data
my_yelp <- read_rds(here("Lab", "module_1", "week2", "yelp_all.rds"))
# Issue 2 ------------------------------
# We do have many duplicated rows in our data, which is expected.
# Luckily, Yelp data provides a unique ID column for each business.
yelp_unique <- my_yelp %>%
distinct(id, .keep_all=T)
# Issue 3 ------------------------------
# This is the main issue in Yelp data, caused by the original data format being JSON.
yelp_flat <- yelp_unique %>%
# 1. Flattening columns with data frame
jsonlite::flatten() %>%
# 2. Handling list-columns
mutate(transactions = transactions %>%
map_chr(., function(x) str_c(x, collapse=", ")),
location.display_address = location.display_address %>%
map_chr(., function(x) str_c(x, collapse=", ")),
categories = categories %>% map_chr(concate_list)) # concate_list is the custom function
# Issue 4 ------------------------------
# Let's first check whether there are any NAs.
yelp_flat %>%
map_dbl(., function(x) sum(is.na(x)))
# --> There seems to be many missing values in 'price' and 'location' columns.
# Remember that you do not need to drop rows just because the row has NAs
# in some columns IF YOU DON"T NEED THAT COLUMN FOR YOUR ANALYSIS.
# In this dataset, missing values in location.address1 are not problem because we have coordinate information.
# We, however, must drop the four NAs in coordinates.latitude and coordinates.longitude.
# Sf package cannot handle NAs in coordinates.
# Fist, let's verify that the 4 missing values in lat/long columns are in the same rows.
identical(is.na(yelp_flat$coordinates.latitude),
is.na(yelp_flat$coordinates.longitude)) # Yes, they are in the same 4 rows.
# Drop them.
yelp_dropna1 <- yelp_flat %>%
drop_na(coordinates.longitude)
# Missing values in 'price' column can be an issue, as that's one of the main variables.
# Assuming that we will be using the price column, let's drop NAs in 'price' column too.
yelp_dropna2 <- yelp_dropna1 %>%
drop_na(price)
# census boundary
census <- st_read("https://raw.githubusercontent.com/BonwooKoo/UrbanAnalytics2022/main/Lab/module_0/testdata.geojson")
# Converting yelp_dropna2 into a sf object
yelp_sf <- yelp_dropna2 %>%
st_as_sf(coords=c("coordinates.longitude", "coordinates.latitude"), crs = 4326)
# sf subsets
yelp_in <- yelp_sf[census %>%
filter(county %in% c("Fulton County", "DeKalb County")) %>%
st_union(), ,op = st_intersects]
glue::glue("nrow before: {nrow(my_yelp)} -> nrow after: {nrow(yelp_in)} \n
ncol before: {ncol(my_yelp)} -> ncol after: {ncol(yelp_in)} \n") %>%
print()
# Visualize
tmap_mode("view")
tm_shape(yelp_in) + tm_dots(col = "price")
# census is currently sfc. Convert it to sf.
census_sf <- census %>% st_sf()
# Spatial join
census_yelp <- st_join(census_sf, yelp_in, join = st_intersects)
yelp_census <- st_join(yelp_in, census_sf, join = st_intersects)
# View
census_yelp %>% head()
yelp_census %>% head()
tm_shape(census_yelp) + tm_polygons(col = "review_count")
names(yelp_in)
tm_shape(census_yelp) + tm_polygons(col = "rating", style = "quantile")
yelp_census
yelp_census %>% head()
head(census_yelp)
tm_shape(census_yelp %>% group_by(GEOID) %>% summarise(rating=mean(rating))) +
tm_polygons(col = "rating", style = "quantile")
tm_shape(census_yelp %>% group_by(GEOID) %>% summarise(rating=sd(rating))) +
tm_polygons(col = "rating", style = "quantile")
tm_shape(census_yelp %>% group_by(GEOID) %>% summarise(rating=mean(rating))) +
tm_polygons(col = "rating", style = "quantile")
tm_shape(yelp_census) + tm_dots(col="hhincome")
yelp_in %>% count(rating)
yelp_in %>% count(price)
?case_when
yelp_in
yelp_in %>%
# Use mutate bc the re-coded variable is a new variable
mutate(review_count_binary = case_when(review_count > 1000 ~ "many",
review_count <= 1000 ~ "few")) %>%
select(review_count, review_count_binary) %>%
head()
yelp_in %>%
mutate(across(is.numeric, scale))
yelp_in %>%
mutate(across(is.numeric, scale)) %>%
select(is.numeric)
my_yelp
my_yelp %>% select(id, categories, transactions, coordinates, location) %>% slice(1:10) %>% write_rds(here("Lab", "module_1" "week2", "yelp_subset.rds"))
my_yelp %>% select(id, categories, transactions, coordinates, location) %>% slice(1:10) %>% write_rds(here("Lab", "module_1", "week2", "yelp_subset.rds"))
# Read a subset of Yelp data we downloaded last week
yelp_subset <- read_rds(here("Lab", "module_1", "week2", "yelp_subset.rds"))
# Print to see what's inside
yelp_subset %>%
tibble() %>%
print(width = 1000)
yelp_subset$coordinates %>% head()
glue::glue("Before dropping NA, there were {nrow(my_yelp)} rows. After dropping them, there are {nrow(yelp_unique)} rows")
is.character(glue::glue("Before dropping NA, there were {nrow(my_yelp)} rows. After dropping them, there are {nrow(yelp_unique)} rows"))
xaringan:::inf_mr()
xaringan:::inf_mr()
xaringan:::inf_mr()
?save.image
map(1:5, # input vector
function(x) x + 1) # anonymous function
map(1:5,
function(x){
out <- (x + 1)*x
return(out)
})
?map_lgl
point_df <- data.frame(x = c(-84.3991, -84.4010, -84.3899), y = c(33.7770, 33.7748, 33.7777))
point_df <- data.frame(x = c(-84.3991, -84.4010, -84.3899), y = c(33.7770, 33.7748, 33.7777))
xaringan:::inf_mr()
xaringan:::inf_mr()
"https://teams.microsoft.com/l/meetup-join/19%3a3a350b1c620f43cd96f8a5ec6a5c7184%40thread.tacv2/1663084901371?context=%7b%22Tid%22%3a%22482198bb-ae7b-4b25-8b7a-6d7f32faa083%22%2c%22Oid%22%3a%22f75ad2af-267d-454f-b064-83f7f6b0eae5%22%7d" == "https://teams.microsoft.com/l/meetup-join/19%3a3a350b1c620f43cd96f8a5ec6a5c7184%40thread.tacv2/1663084901371?context=%7b%22Tid%22%3a%22482198bb-ae7b-4b25-8b7a-6d7f32faa083%22%2c%22Oid%22%3a%22f75ad2af-267d-454f-b064-83f7f6b0eae5%22%7d"
xaringan:::inf_mr()
