---
title: "Data for Urban Analytics"
subtitle: ""
author: "Bon Woo Koo & Subhro Guhathakurta"
institute: "Georgia Institute of Technology"
date: "2022/8/30"
output:
  xaringan::moon_reader:
    css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    seal: false
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '4:3' # alternatives '16:9' or '4:3' or others e.g. 13:9
---
class: middle, inverse

# Data for Urban Analytics

.font100[
Bon Woo Koo & Subhro Guhathakurta

8/30/2022
]

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#1c5253",
  header_font_google = google_font("Open Sans"),
  text_font_google   = google_font("Source Sans Pro", "400", "400i"),
  code_font_google   = google_font("Fira")
)

nice_table <- function(df, height="150px"){
  return(
    df %>% kable() %>% 
      kable_styling(latex_options="scale_down", font_size=12) %>% 
      scroll_box(width = "100%", height = height)
    )
}
```

```{r, include=F}
library(xaringanthemer)
library(sf)
library(tidyverse)
library(leaflet)
library(tmap)
library(kableExtra)
```

---


## Data for Urban Analytics

**Big data is not just about size.** If the size was all that makes a data big, then there is nothing new about big data; we've had it for a long time. For example,

* National Decennial Census <br> .footnotesize[.gray[(which technically covers the entire population; hundreds of millions)]]
* Survey response for electoral predictions <br> 
  .footnotesize[.gray[(e.g., The famous 2.4 million survey responses by Literary Digest in 1936, which, despite the size, miserably failed)]]

.center[
### The characteristics of data that gave rise to urban analytics is more complex.
]
---
## Characteristics of Big Data

Kitchin (2014) details that big data can be characterized by: 

* **Volume**, consisting of terabytes or petabytes of data;  
* **Velocity**, being created in or near real-time;  
* **Variety**, being structured and unstructured in nature;


--

And goes on to include:

* **Exhaustive** in scope, striving to capture entire populations or systems (n=all);

* fine-grained in **resolution**, aiming to be as detailed as possible;

* **relational** in nature, containing common fields that can join different data sets;

* **flexible** (can add new fields easily) and **scaleability** (can expand in size rapidly).

---
##  Challenges that Big Data introduces

* **Volume** &#8594; Need for more efficient algorithms or more powerful computers. **Can't use Excel.** <font size=3px, color="grey"> (capped at 1 million rows by ~16K columns; [source](https://support.microsoft.com/en-us/office/excel-specifications-and-limits-1672b34d-7043-467e-8e27-269d656771c3)) </font>

--

* **Velocity** &#8594; Need for more direct & automated access to the data storage.

--

* **Variety** &#8594;  Need for new analytical techniques to convert unstructured data into structured formats. <br> 
.footnotesize[.gray[*E.g., having all the street view images in the world won't do much good if there was no automated image processing. We can't insert images into a regression analysis.*]]

--

.center[
<font size=6px, color='darkgreen'> These challenges require that we combine <br>"innovative statistical methods, novel comptuer science, and original theories" (King, 2016, pp. ix-x) </font>
]

---
# Sources of Big Data

* Directed -> "generated by traditional forms of surveillance, wherein the gaze of the technology is focused on a person or place by a human operator" (Kitchin 2014, p.4). Satellite and LiDAR images,  Google Street View images. **Module 3**

* Automated -> "generated as an inherent, automatic function of the device or system" (Kitchin 2014, p.4). GPS from cell phones, transaction records and clickstream on e-commerce websites such as Amazon, and tap-in and tap-out records from public transportation  systems **Module 1**

* Volunteered -> generated by users. Postings on social media such as Twitter, Facebook and Reddit, images and videos uploaded by users, reviews and tips left on Google Places and Yelp, and user-contributed large databases such as OpenStreetMap. **Module 2**

---
Many of these big data are unstructured. Only about 5 percent of all existing data are
structured (that is, tabular data in a spreadsheet or similar formats) while the rest is not
in these formats (Cukier 2010; Gandomi and Haider 2015)

Unstructured data, such as
images, audio, video and unstructured texts, often need to be translated to into structured
formats required by analysis and modelling conventions (Gandomi and Haider 2015). 

Many data coming from sensors and wireless networks (for example, smartphones) are
inherently spatial and spatiotemporal (Jardak et al. 2014). A study in 2012 noted that Google generates
about 25 petabytes of data per day, and a significant portion of the data has spatiotemporal components (Vatsavai et al. 2012).

In addition to relational data, the spatial dimension
of big data offers important insights and allows researchers to gain greater value from the
data by, for example, joining different datasets that are otherwise disconnected.