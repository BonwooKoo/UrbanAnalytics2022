---
title: "Intro to Urban Analytics"
author: "Bon Woo Koo & Subhrajit Guhathakurta"
date: '2022-08-20'
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
    code_folding: show
---

```{r,message=FALSE}
tidycensus::census_api_key(Sys.getenv("census_api"))
library(tidycensus)
library(sf)
library(tmap)
library(jsonlite)
library(tidyverse)
library(httr)
library(jsonlite)
library(reshape2)
library(here)
library(yelpr)
library(knitr)
```
<style type="text/css">
  body{
  font-family: Arial;
  }
</style>

# Download data from Census 2020

Here we are downloading income, race, and means of transportation to work

```{r, results="hide"}
FD_tract <- suppressMessages(
  get_acs(geography = "tract", # or "block group", "county", "state" etc.
          state = "GA",
          county = c("Fulton", "Dekalb"),
          variables = c(hhincome = 'B19019_001',
                        race.tot = "B02001_001",
                        race.white = "B02001_002",
                        race.black = "B02001_003",
                        trans.total = "B08006_001",
                        trans.car = "B08006_002",
                        trans.drovealone = "B08006_003",
                        trans.carpooled = "B08006_004", # Notice that I was not interested in 005-007 (2 person/ 4 person carpool etc.)
                        trans.pubtrans = "B08006_008", # Did not want to download any details about the type of public transport (009-0013)
                        trans.bicycle = "B08006_014",
                        trans.walk = "B08006_015",
                        trans.WfH = "B08006_017"
          ),
          year = 2020,
          survey = "acs5", # American Community Survey 5-year estimate
          geometry = TRUE, # returns sf objects
          output = "wide") # wide vs. long
)
```

<br>

The data contains several redundant columns that we will not use. So, let's subset the data to only have the columns we will use

```{r, message=FALSE}
FD_tract <- FD_tract %>%
  select(GEOID,
          hhincome = hhincomeE, # New name = old name
          race.tot = race.totE,
          race.white = race.whiteE,
          race.black = race.blackE,
          trans.total = trans.totalE,
          trans.car = trans.carE,
          trans.drovealone = trans.drovealoneE,
          trans.carpooled = trans.carpooledE,
          trans.pubtrans = trans.pubtransE,
          trans.bicycle = trans.bicycleE,
          trans.walk = trans.walkE,
          trans.WfH = trans.WfHE)

tmap_mode("view")
## tmap mode set to interactive viewing
tm_shape(FD_tract) + tm_borders()
```

# Reading Yelp data

**To save time in class, we will use the Yelp data that Bonwoo downloaded for today's class.**

The Yelp data can be found on **Canvas > Files > yelp_yoga.geojson.** This data is for Fulton and DeKalb County, GA, and contains Yelp data with categories = "yoga". This data is already cleaned. 

To read the data into R, we will use st_read() function in sf package. Notice that in the code below, only the name of the .geojson file is specified. This works only when the file is in the same folder as your .Rmd file. If not, you will need to provide a full path to the file.

```{r}
# Reading the yelp data
yelp_in <- st_read("yelp_yoga.geojson")
```


# Appending Census data
Here, we will append Yelp data to Census data using st_join(). If you can't remember how the code works, look at [this slide](https://bonwookoo.github.io/UrbanAnalytics2022/Lab/module_0/w2_d2_Intro_to_R_2.html#37).

```{r}
# Transforming CRS of census to match that of Yelp data .
# st_join() requires that the CRS are the same for two data.
census_sf <- FD_tract %>% st_sf() %>% st_transform(crs = 4326)
# Spatial join. Notice the order of arguments.
yelp_census <- st_join(yelp_in, census_sf, join = st_intersects)

yelp_census %>% head(3)
```

# Start exploring the data -- look for summary stats, outliers, and associations
Let's use skim() function to get a summary of the data.

Notice that the data file has a few missing values - we will not worry about the ones we will not use.
We will use household income -- so let's drop the two missing values from hhincome.

```{r}
library(skimr)
# skim your data
print(skim(yelp_census))

# Dropping the two missing values
yelp_census_dropnaHH2 <- yelp_census[!is.na(yelp_census$hhincome),]

# Just to check whether the 2 NAs have been dropped
print(skim(yelp_census_dropnaHH2))
# To check if it is still a sf file
class(yelp_census_dropnaHH2) 
```

## Let's ask some probing questions about the data
1. Are people driving alone living in tracts with high median hh incomes?

We could use the following ggplot command.

```{r}
ggplot(yelp_census_dropnaHH2, aes(x=hhincome, y=trans.drovealone)) + 
  geom_point() + 
  ylab("Number of commuters who drive alone by car")
```



Think about whether "number" of commuters who drive alone is the right variable to check against hhincome when you are seeking to explore the relationship between income and the use of cars.

The number of people who drive alone may be low if there are fewer people commuting in high income neighborhoods. So ideally you want to use PERCENT of commuters who drive alone rather than the number.

```{r}
yelp_census2 <- yelp_census_dropnaHH2 %>%
  mutate(prop_drovealone=trans.drovealone/trans.total)

ggplot(yelp_census2, aes(x=hhincome, y=prop_drovealone)) + 
  geom_point() + 
  ylab("Proportion of commuters who drive alone by car")
```


Do you notice a difference from the previous plot?

```{r}
yelp_census3 <- yelp_census2 %>%
  mutate(prop_white = race.white/race.tot, prop_black=race.black/race.tot)

```

Let us now check whether race has a association with drive alone

```{r}
ggplot(yelp_census3, aes(x=prop_white, y=prop_drovealone)) + 
  geom_point() + 
  ylab("commuters who drive alone by car by race = white")

```


Where are the people who drive alone?

```{r}
tmap_mode("view")
tm_shape(yelp_census3) + 
  tm_dots(col="prop_drovealone")
```


What about work from home?

```{r}
yelp_census4 <- yelp_census3 %>%
  mutate(prop_wfh=trans.WfH/trans.total)

ggplot(yelp_census4, aes(x=hhincome, y=prop_wfh)) + 
  geom_point() + 
  ylab("Workers working from home")
```


## Adding a smoothed line 

You can also fit a smoothed line to the scatterpolt
```{r}
scatter.smooth(yelp_census4$prop_wfh, 
               yelp_census4$hhincome, 
               xlab="Household Income", 
               ylab="Proportion of workers working from home", 
               main="Work from Home by Household Income")
```


## Simple correlations between two variables
How strong is the relationship between income and work from home? Measures of association are dependent upon the type of variables: nominal, ordinal, or ratio. Since the measures here are ratio variables, we will use the correlation coefficient.

Use > **cor(x, use=, method=)**

```{r}
cor(yelp_census4$prop_wfh, 
    yelp_census4$hhincome, 
    use="pairwise.complete.obs", 
    method="pearson")
```


## Bivariate regression
What about a bivariate regression to examine the relationship between work from home and income? Which variable should be the dependent?

```{r}
regress_wfh <- lm(yelp_census4$prop_wfh ~ yelp_census4$hhincome)
summary(regress_wfh)
```

## Plot the regression line

```{r}
plot(yelp_census4$hhincome, 
     yelp_census4$prop_wfh, 
     main = "Regression for Work from Home and income", 
     xlab="Household Income", 
     ylab="Percent working from home")

abline(lm(prop_wfh~hhincome, data=yelp_census4), col="red")
```


Can you examine some other measures of associations? Work from home vs. income? What about Yoga studios vs. income.