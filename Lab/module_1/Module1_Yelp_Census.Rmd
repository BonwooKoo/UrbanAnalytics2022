---
title: "Census & Yelp API"
author: "Bonwoo Koo & Subhrajit Guhathakurta"
date: '2022-09-06'
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# New functions introduced in this document

Function                Description
---------------------   ---------------
tidycensus::get_acs     Downloads ACS data
sf::st_bbox             Get the bounding box 
sf::st_point            Create POINT simple feature geometry
sf::st_centroid         Get the centroid of a geometry
sf::st_distance         Calculate Euclidian distance between pairs of geometries
sf::st_geometry         Get geometry from an sf object
sf::st_transform        Transform coordinates of sf object
sf::st_coordinates      Get coordinates in matrix form
sf::st_set_geometry     Set geometry of an sf object
sf::st_as_sf            Convert foreign object to an sf object
sf::st_join             Spatial join
sapply                  Apply a function over a list or vector
min                     Return the minima of the input values
max                     Return the minima of the input values
abs                     Return absolute valueof the input value
seq                     Generate a regular sequences
expand.grid             Create a data.frame from all combinations of supplied vectors or factors.
names                   Get (or set) the names of an object
paste0                  Concatenate vectors after converting to character
ceiling                 Returns a numeric vector containing the smallest integers not less than x
bind_rows               Binding rows of data.frames into one.
Sys.getenv              Access the values of the environment variables              
list.files              Returns a character vector of the names of files or folder in the named folder.
units::set_units        Creates object of class units 
osmdata::getbb          Uses the free Nominatim API provided by OpenStreetMap to find the bounding box (bb) associated with place names.
yelpr::business_search  Search bussiness on Yelp using Yelp Fusion API's business search endpoint
jsonlite::flatten       Flattens nested data frame (i.e., data frames with one or more columns consisting of another data frame)
purrr::map_lgl          Funtional that returns a logical vector



# Getting data through API
In this document, we will use API (application programming interface) to acquire data from the Census Bureau & from Yelp Fusion API. According to Wiki, "An API is a way for two or more computer programs to communicate with each other." To use API, we generally need to connect to the endpoint of API server, which often looks something like `https://api.yelp.com/v3`. We then append other parameters to complete it. 

For example, the following is requesting **business search** service using a keyword **delis** for the location latitude of 37.787 and longitude of -122.399.

> `https://api.yelp.com/v3/businesses/search?term=delis&latitude=37.786882&longitude=-122.399972`

In our everyday terms, think of this as a data request application form. Once this 'form' is created, we need to send this 'form' to the server (i.e., the data provider). We would use e.g., `GET()` function in **httr package** to send API request to the server, and the server would return something like the following to the authenticated requests.

![](json_response_eg.JPG)

This JSON format can be reformatted into a data.frame format using e.g., **jsonlite** and **reshape2** packages. 



# Understanding Yelp Business Search
All APIs are different. Being familiar with Yelp Fusion API does not tell you anything about how Google Street View API is structured. So the first thing you need to do is to [**READ THE DOCUMENTATION OF YELP FUSION API**](https://www.yelp.com/developers/documentation/v3/get_started).

Yelp Fusion API has various endpoints: Business Search, Phone Search, Transaction Search, Business Details etc. You will notice that for everyting except **Business Search**, you need to have some information about the business you are looking for (e.g., business id, phone number, exact location, etc). Business Search allows us to search business by keywords (e.g., Ray's), catergories (e.g., cafe), location (e.g., coordinates), etc. **This is what we need.** Let's look at the related parameters of [Business Search](https://www.yelp.com/developers/documentation/v3/business_search).

1. The Business Search takes various input parameters, some optional and others required. Most importantly, we need to provide **geographic information** in which we want to do a search. We can provide it through one of the following ways: 

  * `location` parameter: E.g., New York City, NYC, 350 5th Ave, etc.
  * `longitude and latitude` parameter: E.g., 33.7484, -84.3902.
  * `radius` parameter: Search radius. Note that the actual search radius may vary. Max 40,000 meters.

2. Other important parameters are `limit` and `offset`.

  * `limit` parameter: Number of business results to return. For results of more than 50 businesses, Yelp returns results in **multiple pages**. The `limit` parameter determines how many businesses are contained in one page.
  * `offset` parameter: This parameter defines from which **page** we want the data. For example, with `limit` of 50, the 51th business will be in the second page.

An important limitation of the Business Search in Yelp Fusion API is that **it returns up to 1,000 businesses based on the provided search criteria**. It means if you request Yelp to return all restaurants in Atlatna using one search criteria, you may not get all the restaurants in Atlanta if there are more than 1000 of them in Atlanta. **You would need to break your search into smaller bits to ensure that you get less than 1000 hits for each search criteria**.



> **There is [Yelp Open Dataset](https://www.yelp.com/dataset). Why not use this instead?** <br> It is a subset of the businesses, reviews, and user data for use in personal, educational, and academic purposes, containing 6,990,280 reviews and 150,346 businesses from 11 metropolitan areas. <br><br> However, I do not know whether this data is a sample or not. If it is a sample, we would need to know the sampling method, when the sampling was done, when the update will be made, etc. In other words, we don't have information on velocity and exhaustivity of the data. Without these information, we cannot assess whether findings from this dataset is biased or not.




# Downloading Census Track Polygons through Census API
In this document, we will use Census Tract boundary as a device to break down the city of Atlanta into smaller bits so that one search criteria would not generate more than 1000 hits. Census Tract is useful for this purpose because, by definition, the size of Census Tracts is proportional to the population size. Assuming that there are more POIs in more populous area, we can *roughly* expect that the size of Census Tracts would be proportional to the POI numbers. 

The Census bureau provides API. There is a convenient R package that makes accessing Census API easy, called *tidycensus*. The package has **get_acs()** function that can download American Community Service (ACS) directly into your R session as an sf object.

## Census API Key
First of all, we need to acquire Census API Key. Go to [https://api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html) and input Organization Name and Email Address. You will get a key emailed to your email account. You need to then use `census_api_key("your-API-key-here")` to do the authentication. 

> **Remember that everything on Rpubs is public. If you include your API key in R Markdown, it will be public as well. This is DANGEROUS. Instead, you can store the key as your environment variable and call it using *Sys.getenv()* function. For example, my Census API Key is stored in Environment Variables as "census_api". I can do the following code to authenticate without revealing my actual API key.**

```{r}
tidycensus::census_api_key(Sys.getenv("census_api"))
```


## Getting Census Tract Boundary
To use `get_acs()`, we first need to understand what arguments are needed for this function. Try `?tidycensus::get_acs` in your console to check the documentation for this function.

![](get_acs.JPG)

We will specify the following argument and leave the rest as default: geography, state, county, variables, year, survey, geometry, and output. The returned output from this function is assigned to an R object named `tract`.

Notice that we can also specify **variables** argument. You can provide variable ID to specify the variables you want to download. You can (1) use **load_variables()** function to see all variable ID, (2) go to Census Bureau [website](https://data.census.gov/cedsci/) to see the variable ID, or (3) some other sources. I recommend [NHGIS](https://www.nhgis.org/) for its highly intuitive filtering system.


```{r message=F}
library(tidycensus)
library(sf)
library(tmap)
library(jsonlite)
library(tidyverse)
library(httr)
library(jsonlite)
library(reshape2)
library(here)
library(yelpr)
```

```{r}
#### Tract polygons for the center of Yelp querry
tract <- get_acs(geography = "tract",
                 state = "GA",
                 county = c("Fulton", "Dekalb"),
                 variables = c(hhincome = 'B19019_001',
                               race.tot = "B02001_001", 
                               race.white = "B02001_002", 
                               race.black = 'B02001_003'
                               ),
                 year = 2019,
                 survey = "acs5",
                 geometry = TRUE,
                 output = "wide") %>% 
  select(geo.id = GEOID, 
         hhincome = hhincomeE,
         race.tot = race.totE,
         race.white = race.whiteE,
         race.black = race.blackE)

# Function: Get tract-wise radius
get_r <- function(poly){
  # Get bounding box
  bb <- st_bbox(poly) 
  # Get one point of the bb
  bb_p <- st_point(c(bb[1], bb[2])) 
  # Get centroid of the bb
  c <- st_centroid(poly) 
  # Distance between bb_p and c
  r <- st_distance(bb_p, c)
  return(r)
}

r4all <- tract %>%
  st_geometry() %>% st_transform(crs = 26967) %>% 
  sapply(., function(x) get_r(x))

tract$radius <- units::set_units(r4all,m)

tract.c <- st_centroid(tract) %>% st_transform(4326)
tract.c$x <- st_coordinates(tract.c)[,1]
tract.c$y <- st_coordinates(tract.c)[,2]
tract.c <- tract.c %>% st_set_geometry(NULL)
```

To visualize what `tract.c` means, run the following code.

```{r}
tmap_mode('view')

tract.c[1:10,] %>% 
  st_as_sf(coords = c("x", "y"), crs = 4326) %>%
  st_buffer(., dist = .$radius) %>% 
  tm_shape(.) + tm_polygons(alpha = 0.5, col = 'red') +
  # Comparison to the original polygon
  tm_shape(tract[1:10,]) + tm_borders(col= 'blue') 

# Look at geo.id == '13121009502'.
# Why is the buffer a bit too large than the polygon while other tracts have correctly sized circles?
```

| Quiz: Look at GEOID = 13121009502. You will notice that the radius is slightly too large for the Census Track. Other tracks will display circles that fits the size of Census Tract much better. Why do you think this happened?


An alternative way to get a similar result is shown below. To see what the code below does, you can copy the code and run it in the console.

```{r eval=FALSE}
# Get bb for two counties
fulton_bb <- osmdata::getbb("Fulton County, GA")
dekalb_bb <- osmdata::getbb("DeKalb County, GA")

# Find coordinates for the four sides of the bb
left_x <- min(c(fulton_bb[1,],dekalb_bb[1,])) # <<-- smaller , larger(i.e., closer to zero) -->>
right_x <- max(c(fulton_bb[1,],dekalb_bb[1,]))
bottom_y <- min(c(fulton_bb[2,],dekalb_bb[2,]))
top_y <- max(c(fulton_bb[2,],dekalb_bb[2,]))

# Break the bb into a grid
fishnet_n <- 40
steps <- abs(left_x - right_x)/fishnet_n


# Fishnet points
fish_x <- seq(from = left_x, to = right_x, by = steps)
fish_y <- seq(from = bottom_y, to = top_y, by = steps)

fishnet <- expand.grid(fish_x, fish_y) %>% 
  rename(x = Var1, y = Var2) %>% 
  st_as_sf(coords = c('x', 'y'), crs = 4326)

# Visualize it
tm_shape(fishnet %>% 
           st_buffer(dist = units::set_units(steps, "degree"))) + tm_polygons(alpha = 0.2, col = 'red')

```


# Defining function for accessing Yelp API

This function below generates a fully-cleaned output. In class, we can provide students with a function that generates raw output (or close to raw) and have them clean it step by step.

After the cleaning process, we can come back to this function and modify the function to embed the cleaning process inside the function.

Mini-quiz -> how to supress messages

```{r}
#### yelp api function
yelp_search <- function(lat, lon, radius, category, api.key){
  # Pagination inddex
  count <- 1
  # Initial run (needed to get $total value)
  json <- business_search(api_key = api.key, 
                          categories = category, 
                          latitude = lat, 
                          longitude = lon, 
                          offset = (count - 1)*50, 
                          radius = radius, 
                          limit = 50) 
  # If there is no match from Yelp
  if (json$total == 0) {
    # Create an empty data.frame 
    json.all <- data.frame(id = NA, name = NA, categories = category, 
                           n.rating = NA, rating = NA, price = NA, is_closed = NA, 
                           lat = NA, lon = NA)
  # Else
  } else {
    # Convert json-like structure into data.frame format
    json.all <- json$businesses %>% 
      jsonlite::flatten() %>% # to eliminate nested structure
      mutate(price = ifelse('price' %in% names(.), price, NA), # If there is no price column
             is_closed = ifelse('is_closed' %in% names(.), is_closed, NA)) %>%  # is there is no is_close column
      select(id, name, categories, 
             n.rating = review_count, 
             rating, price, is_closed, 
             lat = coordinates.latitude, 
             lon = coordinates.longitude) # select & name changes
    
    # Drop rows that have zero entries in category column
    #####################################################
    # Change the code below to simplify it

    # Unlist the category column and create a character string seperated by comma
    # <- This function 'melt' emits many messages. Suppressing them.
    
    cate.title <- suppressMessages({
      reshape2::melt(json.all$categories)
      }) %>% 
      group_by(L1) %>% 
      summarize(categories = paste0(title, collapse = ", "))
    
    
    # Replace category column in the original table with the cleaned one
    json.all$categories <- cate.title$categories
    
    # Get how many querries are required to loop through all matches
    offset_n <- ceiling(json$total / 50)
    
    # Start looping
    while(offset_n > count){
      count <- count + 1
      if (offset_n != count){ # For all loop before the final one
        json <- business_search(api_key = api.key, 
                                categories = category, 
                                latitude = lat, 
                                longitude = lon, 
                                offset = (count - 1)*50, 
                                radius = radius, 
                                limit = 50)
        
      } else { # The final one
        json <- business_search(api_key = api.key, 
                                categories = category, 
                                latitude = lat, 
                                longitude = lon, 
                                offset = (count - 1)*50, 
                                radius = radius, 
                                limit = json$total - 50*(count - 1))
        
      }
      
      # Convert json-like structure into data.frame format
      json.cont <- json$businesses %>% 
        mutate(price = ifelse('price' %in% names(.), price, NA),
               is_closed = ifelse('is_closed' %in% names(.), is_closed, NA)) %>% 
        jsonlite::flatten() %>% select(id, name, categories, 
                                       n.rating = review_count, 
                                       rating, price, is_closed, 
                                       lat = coordinates.latitude, 
                                       lon = coordinates.longitude)
      
      # Some rows do not have category names. It is okay to keep them, 
      # but for the purpose of exercise, let's try dropping such rows.
      category_filter <- map_lgl(json.cont$categories, function(x) length(x[[1]]) != 0)
      
      json.cont <- json.cont[category_filter,]
      
      cate.title <- suppressMessages({
        reshape2::melt(json.cont$categories)
        }) %>% 
        group_by(L1) %>% 
        summarize(categories = paste0(title, collapse = ", "))
      
      json.cont$categories <- cate.title$categories
      
      # This version of code has redundancy. I need to organize it such that 
      # this cleaning process is done once.
      json.all <- bind_rows(json.all, json.cont)
    }
  }
  
  return(json.all)
}
```


```{r}
#### data download 
# API key
api.key <- Sys.getenv('yelp_api') # To Subhro, to use this code, you need to edit your system envirnnment variables. See https://www.howtogeek.com/787217/how-to-edit-environment-variables-on-windows-10-or-11/#:~:text=In%20the%20System%20Properties%20window,%2C%20and%20click%20%E2%80%9COK.%E2%80%9D

# Receiving DF
result.temp <- data.frame(geo.id = integer(0), 
                          id = integer(0), 
                          name = integer(0), 
                          categories = integer(0),
                          n.rating = integer(0), 
                          rating = integer(0), 
                          price = integer(0), 
                          is_closed = integer(0), 
                          lat = integer(0), 
                          lon = integer(0))

# Read yelp.csv if it already exists in your drive
if ("yelp.csv" %in% list.files(getwd())){
  yelp <- read.csv("yelp.csv")
} else {
  # If the file doesn't exist, get it from the Yelp server
  for (i in 1:nrow(tract.c)) {
    temp <- tract.c[i,]
    lat <- temp$y
    lon <- temp$x
    radius <- round(as.numeric(temp$radius))
    json <- yelp_search(lat, lon, radius, 'restaurant', 
                        api.key) %>% 
      mutate(geo.id = temp$geo.id)
    result.temp <- result.temp %>% rbind(json)
    print(paste0("Done with ", i))
  }
  
  # rm(i, json, lat, lon, api.key, radius, temp, tract.c, yelp_search)
  write.csv(result.temp, "yelp.csv")
}

```


*Done!*


# Doing it from the scratch

Shown below is the raw output from the `business_search()` in `yelpr` package.

*I first need to identify what sorts of clean can be done to this file.* If there are other types of cleaning, I will need to show students how to trouble shoot. I might have students to the Googling themselves and have them go through the process themselves in the classroom.

```{r}
# In case you want to see the raw query 
test <- business_search(api_key = Sys.getenv('yelp_api'),
                        category = 'restaurant',
                        latitude = 33.74876295437723,
                        longitude = -84.39073773089834,
                        offset = 1,
                        radius = 1000,
                        limit = 50)
```

```{r}
test_rest <- yelp_search(lat = 33.74876295437723,
                         lon = -84.39073773089834,
                         radius = 1000,
                         category = 'restaurant',
                         api.key = Sys.getenv('yelp_api'))
```

# Cleaning process

## What issues do we see in the raw download?
[API-related issues]
- Pagination.
- Try `class(test)`. What is this that we get from `business_search()` function?
  - test running `jsonlite::flatten(test$businesses) %>% select(coordinates.latitude, coordinates.longitude)` and `test$businesses %>% select(coordinates.latitude, coordinates.longitude)`. The latter will not run.
- Nested data.frame structure
- Inconsistent return columns

[Data cleaning]
- Closed business.
- Missing values.
- Unintuitive values, such as \$ and \$\$ for the price level.
- Category column is not really useful


```{r}
## Saving the R environment
# save.image("D:/Dropbox (GaTech)/Work/Working/School/UA_2022/Lab/W3/yelp_test.RData")
```

# Merging the cleaned data with Census data

One of the most commonly used and basic source of data on wide array of different aspects of life is, of course, the Census data. It is incredibly useful if you can 'join' one geospatial data to census data.

### Converting the downloaded Yelp data to a geospatial data

```{r}
# Converting the POI result into SF
result.sf <- result.temp %>% 
  filter(!is.na(lat) | !is.na(lon)) %>% 
  st_as_sf(coords = c("lon", "lat"), dim = "XY", crs = 4326)
```


### Spatial join the two data
```{r}
# Spatial join the SF to Census data
result.census <- result.sf %>% 
  st_join(tract %>% st_transform(crs = 4326), st_intersects)

# result.census %>% 
#   st_write("D:/Dropbox (GaTech)/Work/Working/School/UA_2022/Lab/W3/restaurant_census.geojson")
```

```{r}
# # Visualize the map
# tmap_mode('view')
# tm_shape(result.census) + tm_dots(col = "hhincome")
```

